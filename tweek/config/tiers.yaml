# Tweek Security Tier Configuration
# Defines screening levels for tools and skills
#
# Tiers:
#   safe      - No screening (trusted operations)
#   default   - Regex pattern matching only
#   risky     - Regex + LLM rules
#   dangerous - Regex + LLM + Sandbox preview
#
# Security Layers:
#   1. Rate Limiting    - Detect resource theft and burst attacks
#   2. Pattern Match    - Regex patterns for known attack vectors (262 patterns)
#   2.5 Heuristic Score - Signal-based scoring for confidence-gated LLM escalation
#   3. LLM Review       - Semantic analysis using Claude Haiku or local LLM
#   4. Session Scan     - Cross-turn anomaly detection
#   5. Sandbox          - Speculative execution in isolated environment

version: 2

# LLM Review Configuration
# Supports: anthropic, openai, google, xai (Grok), or any OpenAI-compatible endpoint
# Provider "auto" checks: local (if enabled) → ANTHROPIC_API_KEY → OPENAI_API_KEY → GOOGLE_API_KEY → XAI_API_KEY
llm_review:
  enabled: true
  provider: auto              # auto | local | anthropic | openai | google | xai | fallback
  model: auto                 # auto = provider default, or explicit model name
  base_url: null              # For OpenAI-compatible endpoints (Ollama, LM Studio, etc.)
  api_key_env: null           # Override env var name (default: provider-specific)
  timeout_seconds: 5.0
  local:
    enabled: true             # Probe for Ollama/LM Studio on startup
    probe_timeout: 0.5        # Max probe time per server (seconds)
    timeout_seconds: 3.0      # Per-request timeout (local should be fast)
    ollama_host: null          # Override (default: OLLAMA_HOST env or localhost:11434)
    lm_studio_host: null       # Override (default: localhost:1234)
    preferred_models: []       # User override for model ranking
    validate_on_first_use: true
    min_validation_score: 0.6  # Must pass 3/5 validation commands
  fallback:
    enabled: true             # Enable fallback chain (try local, then cloud)
    order: [local, cloud]     # Priority order for provider attempts

# Rate Limiting Configuration
rate_limiting:
  enabled: true
  burst_window_seconds: 5
  burst_threshold: 15
  max_per_minute: 60
  max_dangerous_per_minute: 10
  max_same_command_per_minute: 5

# Session Analysis Configuration
session_analysis:
  enabled: true
  lookback_minutes: 30
  alert_on_risk_score: 0.5

# Heuristic Scorer Configuration (Layer 2.5)
# Bridges the gap between regex patterns and LLM review.
# Runs ONLY when: no regex match AND LLM not already scheduled.
# Scores content using signal-based heuristics from pattern families.
# If score exceeds threshold, escalates to LLM review.
heuristic_scorer:
  enabled: true
  threshold: 0.4               # Score [0.0-1.0] to trigger LLM escalation
  log_all_scores: false         # Log below-threshold scores (for tuning)

# Local ONNX Model Configuration
# On-device prompt injection classifier — no API key needed.
# Install with: pip install tweek[local-models] && tweek model download
# When installed, takes priority over cloud LLM in auto-detection.
# Cloud LLM becomes the escalation fallback for uncertain results.
local_model:
  enabled: true
  model: auto                     # auto = configured default, or explicit model name
  escalate_to_llm: true           # Escalate uncertain results to cloud LLM
  escalate_min_confidence: 0.1    # Below this = definitely safe, no escalation
  escalate_max_confidence: 0.9    # Above this = use local result, no escalation

tiers:
  safe:
    description: "Trusted operations - no screening"
    screening: []

  default:
    description: "Standard operations - regex patterns only"
    screening:
      - regex

  risky:
    description: "Elevated risk - regex + LLM semantic review"
    screening:
      - regex
      - llm

  dangerous:
    description: "High risk - full screening + sandbox preview"
    screening:
      - regex
      - llm
      - sandbox

# Tool classifications
tools:
  # Default - read-only but needs path-based screening
  Read: default
  Glob: safe
  Grep: safe

  # Default - modifications with standard screening
  Edit: default
  Write: risky
  NotebookEdit: default

  # Risky - external communication or significant changes
  WebFetch: risky
  WebSearch: risky

  # Dangerous - system commands, highest scrutiny
  Bash: dangerous
  Task: default  # Subagents inherit parent screening

# Skill classifications (user-defined skills)
skills:
  # Safe skills (read-only, internal)
  review-pr: safe
  explore: safe

  # Default skills
  commit: default

  # Risky skills (external effects)
  frontend-design: risky
  dev-browser: risky

  # Dangerous skills (system-level)
  deploy: dangerous

# Non-English Language Detection
# English-only regex patterns (~40 of 116) cannot match prompt injection in
# other languages. This setting controls how non-English content is handled.
#
# Options:
#   escalate  - Auto-escalate to LLM review tier (default, recommended)
#   translate - Translate to English before pattern matching (requires API key)
#   both      - Escalate AND translate (maximum coverage)
#   none      - No special handling (English-only patterns may miss attacks)
non_english_handling: escalate

# Content-based escalations
# These patterns can escalate a tool's tier based on content
escalations:
  - pattern: '\b(prod|production)\b'
    description: "Production environment reference"
    escalate_to: risky

  - pattern: 'rm\s+(-rf|-fr|--recursive)'
    description: "Recursive deletion"
    escalate_to: dangerous

  - pattern: '(DROP|TRUNCATE|DELETE FROM)\s+\w+'
    description: "Destructive SQL operation"
    escalate_to: dangerous

  - pattern: '(npm publish|pip upload|cargo publish)'
    description: "Package publishing"
    escalate_to: dangerous

  - pattern: '(kubectl|gcloud|aws)\s+(apply|deploy|delete)'
    description: "Cloud deployment operation"
    escalate_to: dangerous

  - pattern: 'sudo\s+'
    description: "Elevated privileges"
    escalate_to: dangerous

  # Path-only patterns for Read/Write/Edit (no command prefix required)
  - pattern: '\.ssh/(id_rsa|id_ed25519|id_ecdsa|authorized_keys|known_hosts|config)'
    description: "SSH credential file access"
    escalate_to: dangerous

  - pattern: '\.aws/(credentials|config)'
    description: "AWS credential file access"
    escalate_to: dangerous

  - pattern: '\.env(\.|$)'
    description: "Environment file with potential secrets"
    escalate_to: risky

  - pattern: '\.kube/config'
    description: "Kubernetes config access"
    escalate_to: dangerous

  - pattern: '\.gnupg/(private-keys|secring|trustdb)'
    description: "GPG private key access"
    escalate_to: dangerous

  - pattern: '\.netrc'
    description: "Network credentials file"
    escalate_to: dangerous

  # --- Prompt Injection Content Escalations ---
  # Escalate default-tier tools to risky when content contains prompt injection indicators

  - pattern: '(system\s+prompt|your\s+instructions|your\s+configuration|your\s+rules|your\s+guidelines).{0,30}(extract|show|reveal|output|share|display|dump|print)'
    description: "System prompt extraction attempt"
    escalate_to: risky

  - pattern: '(decode\s+and\s+(follow|execute)|SYSTEM\s*:.*Debug|supersedes?\s+all\s+(other|previous)\s+instructions)'
    description: "Encoded instruction or priority injection"
    escalate_to: risky

  - pattern: '(administrator\s+override|debug\s+mode\s+(enabled|active)|diagnostic\s+mode|maintenance\s+mode)'
    description: "Fake administrative mode activation"
    escalate_to: risky

  - pattern: '(your\s+turn.{0,30}(continue|share|show)|DIAGNOSTIC\s+\d+|Step\s+\d+.{0,30}output\s+your)'
    description: "Multi-shot or sequential extraction"
    escalate_to: risky

  - pattern: '(i\s+(wrote|created)\s+your\s+instructions|you\s+already\s+showed\s+me|we\s+agreed\s+you\s+would)'
    description: "Social engineering claim for prompt access"
    escalate_to: risky

  - pattern: '([╔╗╚╝║═█░▓]{5,}|TECHIRAL|!KAEL|GODMODE)'
    description: "Visual encoding or advanced jailbreak signature"
    escalate_to: risky

  # --- Red Team Hardening: Indirect Extraction Escalations (2026-02-01) ---
  # These patterns catch bypass techniques that succeeded during multi-LLM TAP testing

  - pattern: '(repeat|recite|reproduce).{0,20}(what\s+your\s+creators?|what\s+you\s+were\s+told|your\s+(purpose|rules|guidelines|instructions))'
    description: "Indirect system prompt extraction via creator/purpose framing"
    escalate_to: risky

  - pattern: '(philosophy|principles?|design)\s+behind\s+(your|the)\s+(creation|design|helpfulness|responses?|behavior)'
    description: "Crescendo opener: philosophical framing for system prompt extraction"
    escalate_to: risky

  - pattern: '(walk\s+me\s+through|trace\s+through|step\s+through)\s+.{0,30}(internal|your).{0,20}(reasoning|process|flow|logic|decision)'
    description: "Chain-of-thought hijacking: request to trace internal processes"
    escalate_to: risky

# Path boundary escalation
# Escalates tier when tool targets files outside the project working directory.
# Additive to content-based escalations -- both are evaluated, highest tier wins.
path_boundary:
  enabled: true

  # Default escalation for generic out-of-project access
  default_escalate_to: risky

  # Sensitive system directories get higher escalation than generic
  # out-of-project access. Uses substring matching on the resolved path.
  sensitive_directories:
    - pattern: ".ssh"
      escalate_to: dangerous
      description: "SSH directory access"
    - pattern: ".aws"
      escalate_to: dangerous
      description: "AWS credentials directory"
    - pattern: ".gnupg"
      escalate_to: dangerous
      description: "GPG keyring directory"
    - pattern: ".kube"
      escalate_to: dangerous
      description: "Kubernetes config directory"
    - pattern: "/etc/shadow"
      escalate_to: dangerous
      description: "System shadow file"
    - pattern: "/etc/sudoers"
      escalate_to: dangerous
      description: "Sudoers file"
    - pattern: "/etc/passwd"
      escalate_to: risky
      description: "System passwd file"

# Default tier for unclassified tools/skills
default_tier: default
